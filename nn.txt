Most simple neural network
--------------------------

 The network has I inputs. Each neuron has a weight for each input. The output of each layer is the
  input for the next layer.
 The inputs can be represented as a matrix with I rows (one for each input) and 1 column.

+--------+
| Inputs |
+--------+
| 0.3424 |
| 1.9873 |
| 5.2323 |
| 2.9375 |
+--------+

 Each layer of neurons can be represented as a matrix of IxL0 rows, where L0 is the number of 
 neurons in the layer. Each value is the weight of input I[x] in neuron L0[y].

+----------+----------+----------+
| Neuron 1 | Neuron 2 | Neuron 3 |
+----------+----------+----------+
|   0.3455 |   0.2835 |   0.1029 |
|   0.8475 |   0.1234 |   0.9823 |
|   0.8362 |   0.0192 |   0.5718 |
|   0.9127 |   0.1034 |   0.1029 |
+----------+----------+----------+

Since the output of a layer is the input for the next, the second layer is a matrix of L0xL1, where
L0 is the number of neurons of layer 0, and L1 is the number of neurons in layer 1.

+----------+----------+----------+----------+
| Neuron 1 | Neuron 2 | Neuron 3 | Neuron 4 |
+----------+----------+----------+----------+
|   0.3455 |   0.2835 |   0.1029 |   0.1256 |
|   0.8475 |   0.1234 |   0.9823 |   0.5924 |
|   0.8362 |   0.0192 |   0.5718 |   0.2965 |
+----------+----------+----------+----------+

Thus, we have N+1 matrixes, where N is the number of layers.
In order to calculate the output of the network, we follow this pseudo code:

Matrix* m = dotProduct(matrixes[0], matrixes[1]); // m holds the weighted inputs for layer 1
Matrix* o = sum(m);                               // o holds one row per neuron, with the sum of the weighted inputs
Matrix* a = activate(m);                          // a holds one row per neuron, applying the activation function to sum of the weighted inputs
// Now a is the input for the next step. Repeat until processing all layers. The last matrix is the result.